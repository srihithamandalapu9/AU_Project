<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Making environment variables accessible in front-end containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/bRQAOiM1CwA/" /><category term="Containers" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="angular" /><category term="environment variables" /><category term="front-end containers" /><category term="react" /><category term="VueJS" /><author><name>Joel Lord</name></author><id>https://developers.redhat.com/blog/?p=861157</id><updated>2021-03-04T18:59:36Z</updated><published>2021-03-04T18:59:36Z</published><content type="html">&lt;p&gt;When &lt;a href="https://developers.redhat.com/topics/containers"&gt;building a container&lt;/a&gt; for a single-page application using any modern &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript framework&lt;/a&gt; (such as Angular, React, or Vue.js), you might find that the configuration settings are different depending on where the container will run. A typical case would be the base URL for your API, which will differ depending on whether you are testing the application or deploying it into production. Developers usually solve this problem using environment variables.&lt;/p&gt; &lt;p&gt;Environment variables typically work on the backend because that is where code runs. But what if your application lives in the user&amp;#8217;s browser? There are many ways around this limitation. In some cases, you might build a server whose endpoint holds the necessary parameters. Another workaround is to use PHP to inject the environment variables as globals in the JavaScript code. Both of these options work, but it would be ideal to inject the environment variables as part of the container build process. That way, you don&amp;#8217;t have to change the codebase, and you can still deliver the application content using a static web server like NGINX.&lt;/p&gt; &lt;p&gt;This article shows you how to inject environment variables directly into your codebase as you build your container.&lt;/p&gt; &lt;h2&gt;JavaScript frameworks in the production build&lt;/h2&gt; &lt;p&gt;It doesn&amp;#8217;t matter which JavaScript framework you use—React, Angular, or Vue.js—because they all work virtually the same way. The framework runs a server that watches the files, and it refreshes the browser when a change is detected. This process is excellent for development purposes but not so much for production servers. All of that code requires too many resources to run. For the application content to work in a web server, we need a build step that minimizes the code and keeps only the necessary parts. We can then create a package using a single page that contains all of the application&amp;#8217;s HTML, JavaScript, and CSS. When a container runs in a production environment, it will serve this minified package.&lt;/p&gt; &lt;p&gt;It turns out that the container-build step that prepares your code for production is also a great place to inject environment variables. We&amp;#8217;ll go through the process in the next sections.&lt;/p&gt; &lt;h2&gt;Create a skeleton application&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s start with a skeleton application built with the command-line interface (CLI) for your JavaScript framework:&lt;/p&gt; &lt;pre&gt;# Angular npx @angular/cli new angular-project # React npx create-react-app react-project # VueJS npx @vue/cli create vue-project &lt;/pre&gt; &lt;p&gt;For your project of choice, create a &lt;code&gt;config.json&lt;/code&gt; file in the &lt;code&gt;/src&lt;/code&gt; folder. This file will contain settings that could change based on the environment. In this case, it will have two properties: One to specify the environment and another one for the base URL of your imaginary API:&lt;/p&gt; &lt;pre&gt;{ "ENV": "development", "BASE_URL": "http://localhost:3000" }&lt;/pre&gt; &lt;p&gt;For simplicity, the application you are using will display those values on the main page. Head over to your main page, import the configuration file, and display both values in that view.&lt;/p&gt; &lt;p&gt;Next, we&amp;#8217;ll look at the application-specific code for Angular, React, and Vue.js.&lt;/p&gt; &lt;h3&gt;Angular&lt;/h3&gt; &lt;p&gt;To import a JSON file, you might need to add the following options to the &lt;code&gt;compilerOptions&lt;/code&gt; of your &lt;code&gt;tsconfig.json&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt; "resolveJsonModule": true, "esModuleInterop": true, "allowSyntheticDefaultImports": true, &lt;/pre&gt; &lt;p&gt;Here are the application components (&lt;code&gt;src/app/app.component.ts&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;import { Component } from '@angular/core'; import Config from "../config.json"; @Component({ selector: 'app-root', templateUrl: './app.component.html' }) export class AppComponent { environment = Config.ENV; baseUrl = Config.BASE_URL; }&lt;/pre&gt; &lt;p&gt;Here is the application HTML (&lt;code&gt;src/app/app.component.html&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&amp;#60;div&amp;#62; &amp;#60;p&amp;#62;Environment: {{ environment }}&amp;#60;/p&amp;#62; &amp;#60;p&amp;#62;Base Url: {{ baseUrl }}&amp;#60;/p&amp;#62; &amp;#60;/div&amp;#62; &lt;/pre&gt; &lt;h3&gt;React&lt;/h3&gt; &lt;p&gt;Here&amp;#8217;s an application config for React (&lt;code&gt;src/App.js&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;import Config from "./config.json"; function App() { const environment = Config.ENV; const baseUrl = Config.BASE_URL; return ( &amp;#60;div&amp;#62; &amp;#60;p&amp;#62;Environment: { environment }&amp;#60;/p&amp;#62; &amp;#60;p&amp;#62;Base Url: { baseUrl }&amp;#60;/p&amp;#62; &amp;#60;/div&amp;#62; ); } export default App;&lt;/pre&gt; &lt;h3&gt;Vue.js&lt;/h3&gt; &lt;p&gt;And here&amp;#8217;s the configuration for Vue.js (&lt;code&gt;src/App.vue&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&amp;#60;template&amp;#62; &amp;#60;div&amp;#62; &amp;#60;p&amp;#62;Environment: {{ environment }}&amp;#60;/p&amp;#62; &amp;#60;p&amp;#62;Base Url: {{ baseUrl }}&amp;#60;/p&amp;#62; &amp;#60;/div&amp;#62; &amp;#60;/template&amp;#62; &amp;#60;script&amp;#62; import Config from "./config.json"; export default { name: 'App', data: () =&amp;#62; { return { environment: Config.ENV, baseUrl: Config.BASE_URL } } } &amp;#60;/script&amp;#62; &lt;/pre&gt; &lt;h2&gt;Multi-stage build containers&lt;/h2&gt; &lt;p&gt;Now, you&amp;#8217;re ready to build the front-end container. For this process, you will use a container to create the production version of the application. Docker will then copy this build function&amp;#8217;s output into a second container, an NGINX server. Once the second container is created, you discard the first container. What&amp;#8217;s left is the NGINX server with the minimal set of files from the prior stage.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s start by creating an image to contain the application. Later, we&amp;#8217;ll come back to apply the environment variables. For this stage, you&amp;#8217;ll do the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a new file called &lt;code&gt;Dockerfile&lt;/code&gt;. The first stage uses a &lt;code&gt;node:14&lt;/code&gt; image to build the production version of the application. Copy over all of your files into the container.&lt;/li&gt; &lt;li&gt;Copy the files, then run an &lt;code&gt;npm install&lt;/code&gt; to fetch the project&amp;#8217;s dependencies and run an &lt;code&gt;npm run build&lt;/code&gt; to create the production assets.&lt;/li&gt; &lt;li&gt;Start the second stage with a &lt;code&gt;FROM nginx:1.17&lt;/code&gt; statement and copy the files from the first stage into this new container.&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: To avoid copying unnecessary files such as the &lt;code&gt;node_modules&lt;/code&gt; folders, create a &lt;code&gt;.docker-ignore&lt;/code&gt; file in the same folder as your &lt;code&gt;Dockerfile&lt;/code&gt; and list the folders to ignore. Also, note that the production code&amp;#8217;s location varies based on the JavaScript framework you are using, so uncomment the line you need. Angular requires that you change the name of your project manually.&lt;/p&gt; &lt;p&gt;Here is the complete Dockerfile at this stage:&lt;/p&gt; &lt;pre&gt;FROM node:14 WORKDIR /app COPY . . RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 WORKDIR /usr/share/nginx/html # Angular # COPY --from=0 /app/dist/&amp;#60;projectName&amp;#62; . # React # COPY --from=0 /app/build . # VueJS # COPY --from=0 /app/dist . &lt;/pre&gt; &lt;p&gt;After creating the Dockerfile, you can build the image and start the container to test it out. Run the following commands and open your browser to &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/"&gt;http://localhost:8080&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;docker build -t front-end. docker run -d -p 8080:80 --rm --name front frontend &lt;/pre&gt; &lt;p&gt;To stop the container after you&amp;#8217;ve tested it, enter:&lt;/p&gt; &lt;pre&gt;docker stop front&lt;/pre&gt; &lt;h2&gt;Inject the environment variables&lt;/h2&gt; &lt;p&gt;Next, you will edit the Dockerfile to inject your environment variables. First, you&amp;#8217;ll overwrite the content of your original &lt;code&gt;config.json&lt;/code&gt; file, then you&amp;#8217;ll tweak the NGINX server to inject the environment variables.&lt;/p&gt; &lt;h3&gt;Overwrite config.json&lt;/h3&gt; &lt;p&gt;Instead of having actual values, each property&amp;#8217;s value will be &amp;#8220;&lt;code&gt;$key&lt;/code&gt;&amp;#8220;. The resulting &lt;code&gt;config.json&lt;/code&gt; looks like this:&lt;/p&gt; &lt;pre&gt;{ ENV: "$ENV", BASE_URL: "$BASE_URL" } &lt;/pre&gt; &lt;p&gt;You will use the &lt;code&gt;envsubst&lt;/code&gt; to change the &lt;code&gt;$KEY&lt;/code&gt; values to the environment variable&amp;#8217;s real value just before the server starts. For this to work, you need to add instructions to the first step of the Dockerfile to include &lt;a target="_blank" rel="nofollow" href="https://stedolan.github.io/jq/manual/"&gt;jq&lt;/a&gt;, a tool that makes it easy to edit the contents of a JSON file from the CLI. Right after the &lt;code&gt;FROM&lt;/code&gt; line in your Dockerfile, add the following to install &lt;code&gt;jq&lt;/code&gt; in the container:&lt;/p&gt; &lt;pre&gt;ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq &lt;/pre&gt; &lt;p&gt;After the files have been copied, you can use &lt;code&gt;jq&lt;/code&gt; to edit the &lt;code&gt;config.json&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json &amp;#62; ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json ./src/config.json &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you want to learn more about the &lt;code&gt;jq&lt;/code&gt; filter used in this example and experiment with other options, you can run it in &lt;a target="_blank" rel="nofollow" href="https://jqterm.com"&gt;jqTerm&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Tweak the NGINX server&lt;/h3&gt; &lt;p&gt;After you&amp;#8217;ve modified the &lt;code&gt;config.json&lt;/code&gt; file, you will tweak the NGINX server to inject the environment variables. To do so, you will need to create a script to be executed before starting the NGINX server.&lt;/p&gt; &lt;p&gt;This file (&lt;code&gt;start-nginx.sh&lt;/code&gt;) contains quite a bit of bash scripting. The first line of the script runs a command to get the names of all existing environment variables and stores those in &lt;code&gt;$EXISTING_VARS&lt;/code&gt;. The script then loops through each JavaScript file in your production folder and replaces any &lt;code&gt;$VARIABLE&lt;/code&gt; with the actual value of that environment variable. Once it&amp;#8217;s done, it starts the NGINX server with the default command:&lt;/p&gt; &lt;pre&gt;#!/usr/bin/env bash export EXISTING_VARS=$(printenv | awk -F= '{print $1}' | sed 's/^/\$/g' | paste -sd,); for file in $JSFOLDER; do cat $file | envsubst $EXISTING_VARS | tee $file done nginx -g 'daemon off;' &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The location of the JavaScript files differs for each framework. The &lt;code&gt;$JSFOLDER&lt;/code&gt; variable is set in the Dockerfile so that you can uncomment the line you need there.&lt;/p&gt; &lt;p&gt;Now, add this file to the container and overwrite the NGINX image&amp;#8217;s default entry point with this new script. Right after the &lt;code&gt;FROM&lt;/code&gt; statement of the second stage, add the following lines for your framework:&lt;/p&gt; &lt;pre&gt;# Angular # ENV JSFOLDER=/usr/share/nginx/html/*.js # React # ENV JSFOLDER=/usr/share/nginx/html/static/js/*.js # VueJS # ENV JSFOLDER=/usr/share/nginx/html/js/*.js COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh &lt;/pre&gt; &lt;p&gt;At the very end of the file, add the new entry point:&lt;/p&gt; &lt;pre&gt;ENTRYPOINT [ "start-nginx.sh" ] &lt;/pre&gt; &lt;p&gt;Your final Dockerfile should look like this one. You can uncomment the required lines and remove all the other commented statements:&lt;/p&gt; &lt;pre&gt;FROM node:14 ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq WORKDIR /app COPY . . RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json &amp;#62; ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json ./src/config.json RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 # Angular # ENV JSFOLDER=/usr/share/nginx/html/*.js # React # ENV JSFOLDER=/usr/share/nginx/html/static/js/*.js # VueJS # ENV JSFOLDER=/usr/share/nginx/html/js/*.js COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh WORKDIR /usr/share/nginx/html # Angular # COPY --from=0 /app/dist/&amp;#60;projectName&amp;#62; . # React # COPY --from=0 /app/build . # VueJS # COPY --from=0 /app/dist . ENTRYPOINT [ "start-nginx.sh" ] &lt;/pre&gt; &lt;h2&gt;Rebuild your image and start the server&lt;/h2&gt; &lt;p&gt;You are now ready to rebuild your image and start the server again, but this time with environment variables. Open your browser at &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/"&gt;http://localhost:8080&lt;/a&gt;, and you should see the application running with the values of the environment variables you&amp;#8217;ve passed to Docker:&lt;/p&gt; &lt;pre&gt;docker build -t frontend . docker run -d -p 8080:80 --rm --name front -e ENV=prod -e BASE_URL=/api frontend &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In summary, here are the steps to make your environment variables accessible in your front-end containers:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Add a &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers/blob/main/config.json"&gt;config.json&lt;/a&gt; file in your &lt;code&gt;/src&lt;/code&gt; folder.&lt;/li&gt; &lt;li&gt;Add the &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers/blob/main/start-nginx.sh"&gt;start-nginx.sh&lt;/a&gt; bash script to your project.&lt;/li&gt; &lt;li&gt;Use the completed &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers/blob/main/Dockerfile"&gt;Dockerfile&lt;/a&gt; to build your project.&lt;/li&gt; &lt;li&gt;Start your container using &lt;code&gt;-e&lt;/code&gt; to specify the environment variables.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Once you&amp;#8217;ve created a Dockerfile following these steps, you can reuse it for any of your JavaScript projects. All the variables in the &lt;code&gt;config.json&lt;/code&gt; will change automatically, and you won&amp;#8217;t need to think about them anymore. You can find the complete source code and examples for the Angular, React, and Vue.js applications used in this article on &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#038;title=Making%20environment%20variables%20accessible%20in%20front-end%20containers" data-a2a-url="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/" data-a2a-title="Making environment variables accessible in front-end containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/"&gt;Making environment variables accessible in front-end containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/bRQAOiM1CwA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;When building a container for a single-page application using any modern JavaScript framework (such as Angular, React, or Vue.js), you might find that the configuration settings are different depending on where the container will run. A typical case would be the base URL for your API, which will differ depending on whether you are testing [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/"&gt;Making environment variables accessible in front-end containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">861157</post-id><dc:creator>Joel Lord</dc:creator><dc:date>2021-03-04T18:59:36Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/</feedburner:origLink></entry><entry><title>Building rootless containers for JavaScript front ends</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/u_E8Yo1oe3o/" /><category term="Containers" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="front end javascript" /><category term="nginx" /><category term="openshift" /><category term="rootless" /><category term="rootless container" /><author><name>Joel Lord</name></author><id>https://developers.redhat.com/blog/?p=861477</id><updated>2021-03-04T08:00:09Z</updated><published>2021-03-04T08:00:09Z</published><content type="html">&lt;p&gt;By default, most &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt; are run as the root user. It is much easier to install dependencies, edit files, and run processes on restricted ports when they run as root. As is usually the case in computer science, though, simplicity comes at a cost. In this case, containers run as root are more vulnerable to malicious code and attacks. To avoid those potential &lt;a href="https://developers.redhat.com/topics/security"&gt;security&lt;/a&gt; gaps, &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; won&amp;#8217;t let you run containers as a root user. This restriction adds a layer of security and isolates the containers.&lt;/p&gt; &lt;p&gt;This article shows you how to run a JavaScript front-end application in a rootless container. The example builds on the code from my previous article, &lt;a href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers"&gt;&lt;i&gt;Making environment variables accessible in front-end containers&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Building a rootless container&lt;/h2&gt; &lt;p&gt;Here is the Dockerfile we&amp;#8217;ll use for our example. As demonstrated in my &lt;a href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/"&gt;previous article&lt;/a&gt;, you can use this Dockerfile to access environment variables from your Angular, React, or Vue.js applications:&lt;/p&gt; &lt;pre&gt;FROM node:14 ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq WORKDIR /app COPY . . RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json | ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json config.json RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 # Angular: ENV JSFOLDER=/usr/share/nginx/html/*.js # React: ENV JSFOLDER=/usr/share/nginx/html/static/js/*.js # VueJS: ENV JSFOLDER=/usr/share/nginx/html/js/*.js COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh WORKDIR /usr/share/nginx/html # Angular: COPY --from=0 /app/dist/ . # React: COPY --from=0 /app/build . # VueJS: COPY --from=0 /app/dist . ENTRYPOINT [ "start-nginx.sh" ] &lt;/pre&gt; &lt;p&gt;This container uses two stages to build the final container. In the first stage, it uses the &lt;code&gt;node:14&lt;/code&gt; image, which is running as root. The build process will eventually discard this container, so you don&amp;#8217;t need to worry about it.&lt;/p&gt; &lt;p&gt;The second-stage container is the one that needs to be secured. The &lt;code&gt;nginx&lt;/code&gt; base image is currently running as root, mainly so that it can run on port 80, which requires privileged access to enable. Once this container is ready to run rootless, it will run on port 8080. You will need to change the default &lt;code&gt;nginx&lt;/code&gt; configuration for the container to run rootless. You will also need to make sure that the server itself is running as an unprivileged user. Finally, the user will need access to several files and folders.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s get started with making this container a rootless one.&lt;/p&gt; &lt;h2&gt;Create the NGINX configuration file&lt;/h2&gt; &lt;p&gt;The first step is to create a new configuration file for NGINX. You can start with the most basic configuration file needed to run NGINX and build it from there:&lt;/p&gt; &lt;pre&gt;worker_processes auto; events { worker_connections 1024; } http { include /etc/nginx/mime.types; server { server_name _; index index.html; location / { try_files $uri /index.html; } } }&lt;/pre&gt; &lt;p&gt;Next, you need to change the server settings to run on port 8080 instead of the default port 80. You&amp;#8217;ll also need to change the default path that NGINX uses to serve files:&lt;/p&gt; &lt;pre&gt;http { ... server { listen 8080; ... location / { root /code; ... } } }&lt;/pre&gt; &lt;p&gt;The final &lt;code&gt;nginx.conf&lt;/code&gt; file should look like this:&lt;/p&gt; &lt;pre&gt;worker_processes auto; events { worker_connections 1024; } http { include /etc/nginx/mime.types; server { listen 8080; server_name _; index index.html; location / { root /opt/app; try_files $uri /index.html; } } }&lt;/pre&gt; &lt;h2&gt;Edit the Dockerfile&lt;/h2&gt; &lt;p&gt;Now that you have a new NGINX configuration file that lets the server run as a regular user, it&amp;#8217;s time to edit the Dockerfile. This modified container will run as user &lt;code&gt;nginx&lt;/code&gt;. In this case, the NGINX base images provide the non-root user.&lt;/p&gt; &lt;p&gt;In the second step of your build, right after you&amp;#8217;ve specified your base image with the &lt;code&gt;FROM&lt;/code&gt; statement, you can copy your new NGINX configuration file to overwrite the default one. Then, create an &lt;code&gt;/opt/app&lt;/code&gt; folder and change its ownership:&lt;/p&gt; &lt;pre&gt;FROM nginx:1.17 COPY ./nginx.conf /etc/nginx/nginx.conf RUN mkdir -p /opt/app &amp;#38;&amp;#38; chown -R nginx:nginx /opt/app &amp;#38;&amp;#38; chmod -R 775 /opt/app &lt;/pre&gt; &lt;p&gt;Don&amp;#8217;t forget to change the &lt;code&gt;JSFOLDER&lt;/code&gt; variable. This will ensure that your environment variables are still injected by the bash script.&lt;/p&gt; &lt;pre&gt;# Angular # ENV JSFOLDER=/opt/app/*.js # React # ENV JSFOLDER=/opt/app/static/js/*.js # VueJS # ENV JSFOLDER=/opt/app/js/*.js &lt;/pre&gt; &lt;h3&gt;Change the file ownership&lt;/h3&gt; &lt;p&gt;Next, you need to give NGINX access to run a series of files and folders for caching and logging purposes. You can change the ownership of all of them in a single &lt;code&gt;RUN&lt;/code&gt; statement, using ampersands to chain the commands:&lt;/p&gt; &lt;pre&gt;RUN chown -R nginx:nginx /var/cache/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/log/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /etc/nginx/conf.d &lt;/pre&gt; &lt;p&gt;NGINX also requires an &lt;code&gt;nginx.pid&lt;/code&gt; file. This file does not exist yet, so you need to create it and assign ownership to the &lt;code&gt;nginx&lt;/code&gt; user:&lt;/p&gt; &lt;pre&gt;RUN touch /var/run/nginx.pid &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/run/nginx.pid &lt;/pre&gt; &lt;h3&gt;Update the group and permissions&lt;/h3&gt; &lt;p&gt;Finally, you will change the group for those files and folders and change the permissions so that NGINX can read and write the folders:&lt;/p&gt; &lt;pre&gt;RUN chgrp -R root /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid &amp;#38;&amp;#38; \ chmod -R 775 /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid &lt;/pre&gt; &lt;h3&gt;Switch to the rootless user&lt;/h3&gt; &lt;p&gt;Now that you&amp;#8217;ve adjusted all the permissions, you can tell Docker to switch over to the &lt;code&gt;nginx&lt;/code&gt; user using the &lt;code&gt;USER&lt;/code&gt; statement. You can then copy the files from the builder step into the &lt;code&gt;/opt/app&lt;/code&gt; folder using the &lt;code&gt;--chown&lt;/code&gt; flag, which makes the files accessible by the &lt;code&gt;nginx&lt;/code&gt; user. Finally, you will tell Docker that this new image uses a different port. Use the &lt;code&gt;EXPOSE&lt;/code&gt; statement for port 8080:&lt;/p&gt; &lt;pre&gt;USER nginx WORKDIR /opt/app COPY --from=builder --chown=nginx . RUN chmod -R a+rw /opt/app EXPOSE 8080 &lt;/pre&gt; &lt;p&gt;The final front-end Dockerfile will look like this:&lt;/p&gt; &lt;pre&gt;FROM node:14 ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq WORKDIR /app COPY . . RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json | ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json config.json RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 # Angular # ENV JSFOLDER=/opt/app/*.js # React # ENV JSFOLDER=/opt/app/static/js/*.js # VueJS # ENV JSFOLDER=/opt/app/js/*.js COPY ./nginx.conf /etc/nginx/nginx.conf RUN mkdir -p /opt/app &amp;#38;&amp;#38; chown -R nginx:nginx /opt/app &amp;#38;&amp;#38; chmod -R 775 /opt/app RUN chown -R nginx:nginx /var/cache/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/log/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /etc/nginx/conf.d RUN touch /var/run/nginx.pid &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/run/nginx.pid RUN chgrp -R root /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid &amp;#38;&amp;#38; \ chmod -R 775 /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh EXPOSE 8080 WORKDIR /opt/app # Angular # COPY --from=0 --chown=nginx /app/dist/ . # React # COPY --from=0 /app/build . # VueJS # COPY --from=0 /app/dist . RUN chmod -R a+rw /opt/app USER nginx ENTRYPOINT [ "start-nginx.sh" ]&lt;/pre&gt; &lt;p&gt;Your new Dockerfile is ready to go! You can test it out by using a &lt;code&gt;docker build&lt;/code&gt; followed by a &lt;code&gt;docker run&lt;/code&gt;. Don&amp;#8217;t forget to map the new port since this container doesn&amp;#8217;t run on port 80 anymore:&lt;/p&gt; &lt;pre&gt;docker build -t frontend . docker run -d -p 8080:8080 --rm --name front -e ENV=prod -e BASE_URL=/api frontend &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;You now have everything needed to run your JavaScript front end in a secure container. You can reuse the image we developed in this article for all of your JavaScript projects, whether you are using Angular, React, or Vue.js. The front end not only runs securely but also lets you inject environment variables into your code. You can find all the examples and source code from this article on &lt;a target="_blank" rel="nofollow" href="http://github.com/joellord/frontend-containers"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#038;title=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" data-a2a-url="https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/" data-a2a-title="Building rootless containers for JavaScript front ends"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/"&gt;Building rootless containers for JavaScript front ends&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/u_E8Yo1oe3o" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;By default, most containers are run as the root user. It is much easier to install dependencies, edit files, and run processes on restricted ports when they run as root. As is usually the case in computer science, though, simplicity comes at a cost. In this case, containers run as root are more vulnerable to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/"&gt;Building rootless containers for JavaScript front ends&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">861477</post-id><dc:creator>Joel Lord</dc:creator><dc:date>2021-03-04T08:00:09Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/</feedburner:origLink></entry><entry><title type="html">Business optimisation architecture - Example vaccine scheduling</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/3NJxyvEvNik/business-optimisation-architecture-example-vaccine-scheduling-.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/p3YFp6gjxCA/business-optimisation-architecture-example-vaccine-scheduling-.html</id><updated>2021-03-04T06:00:00Z</updated><content type="html">Part 4 - Example vaccine scheduling In the previous article from this series we looked at an example architecture for retail planning optimisation. It started with laying out the process of how I've approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. The specific example of how retail organisations can optimise delivery planning, employee rostering, and optimise task assignments was laid out in the architecture blueprint diagram. This article continues on with another specific example that focuses on how retail stores around the world are helping deliver vaccinations through their pharmacies. It walks you through an example optimisation scenario showing how to provide for customer vaccine scheduling. BLUEPRINTS REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common blueprint that was uncovered researching those solutions. It's my intent to provide a blueprint that provides guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architectural blueprint, but I've chosen a format that I hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a look at the details in this blueprint and outline the solution. VACCINE SCHEDULING ARCHITECTURE The example blueprint shown in the figure titled Schematic - Business optimisation (vaccine scheduling) outlines how this type of optimisation ties into your architecture. In this example, starting from the left we see a business owner and developer providing the input needed for the vaccine planning services. These inputs are constraints (both hard and soft), resource availability, and business goals to be achieved.  It's interesting to take a short side trip into the reason that various constraints make putting together a schedule so demanding that special tooling is needed. In the case of vaccination scheduling there are things you need to think about such as: * planning runs need to complete in timely fashion, for example: * ~350k slots should produce a schedule within an hour * runs can be done several times a day * if anyone with a slot cancels, the planning needs to stop it's run and start again * achieve continuous planning * need rules to prevent games the system, for example: * can't request a slot, then cancel if not satisfied with your slot, thereby getting an earlier slot * ensure cancelled slots in schedule go to back of the line * account for vaccine types that can't be given to certain age groups * give priority to second vaccine slot planning over first vaccine slot These are just some of the constraints and conditions that need to be met with regards to designing and executing a planning cycle. Something to think about, right? While this might look like something that the business owner and developer are doing into the fully deployed solution, it's really using the previously covered  showcased in that blueprint. For simplicity, we've included the planning and constraint development aspects here to help with an understanding that business owners are involved. The vaccine planning services can then be triggered or viewed by external systems shown as planners that have been given access through the API management element to start, provide input, or retreive planning optimisation results.  The integration microservices are making extensive use of the planning results to share a vaccine appointment with the user of the frontend application, shown here as a mobile application. Data access is shown at the bottom making use of vaccine center data, vaccine supply data, and customer data. Access for the vaccine planning services is arranged by the integration data microservices allowing for clean separation of integration points between critical demarcation lines of your architecture. While the business owner and developer are working on the constraints and modeling of the needed vaccine planning services, at runtime the rest of the elements in this diagram are leveraging these optimisation planning services to achieve desired outcomes.  The diagram might give the impression that this is a single in store pharmacy solution, but it can also be seen in the context of a centralised architecture in the retail organisation where the external status views are those of satellite stores or warehouses. The stores and warehouses are all looking to make use of the vaccine planning and optimising services for better pharmacy vaccine scheduling. WHAT'S NEXT THIS WAS JUST A SHORT OVERVIEW OF A VACCINE SCHEDULING ARCHITECTURE THAT PROVIDES YOU WITH A MAP TO SOLVE YOUR OWN BUSINESS OPTIMISATION CHALLENGES.  AN OVERVIEW OF THIS SERIES ON THE BUSINESS OPTIMISATION PORTFOLIO ARCHITECTURE BLUEPRINT CAN BE FOUND HERE: 1. 2. 3. 4. CATCH UP ON ANY ARTICLES YOU MISSED BY FOLLOWING ONE OF THE LINKS ABOVE. THIS COMPLETES THE SERIES AND WE HOPE YOU ENJOYED THIS ARCHITECTURE BLUEPRINT FOR BUSINESS OPTIMISATION. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/3NJxyvEvNik" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/p3YFp6gjxCA/business-optimisation-architecture-example-vaccine-scheduling-.html</feedburner:origLink></entry><entry><title type="html">Optimizing COVID-19 vaccination appointment scheduling</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lMx0uG695YE/optimizing-covid-19-vaccination-appointment-scheduling.html" /><author><name>pauljamesbrown</name></author><id>https://blog.kie.org/2021/03/optimizing-covid-19-vaccination-appointment-scheduling.html</id><updated>2021-03-04T00:00:00Z</updated><content type="html">COVID-19 vaccination appointment scheduling has proven to be a world-wide challenge. People eligible for vaccinations haven’t been able to secure appointments despite repeated attempts. Those scheduled for vaccinations sometimes arrive at a vaccination center only to learn that their appointment has been canceled. Others find that they share the same vaccination time window with hundreds of people and must wait in line for hours. However, this doesn’t have to be the case. You can use the OptaPlanner vaccination appointment scheduler quickstart to develop a schedule that is both efficient and fair. The vaccination appointment scheduler uses artificial intelligence (AI) to prioritize people and allocate time slots based on multiple constraints and priorities. It is part of the , available on GitHub. Watch the video or read on to learn more. THE BENEFITS OF A SYSTEM-AUTOMATICALLY-ASSIGNS APPOINTMENT SCHEDULING SYSTEM There are two main approaches to scheduling appointments. The system can either let a person choose an appointment slot (user selects) or the system assigns a slot and tells the person when and where to attend (system automatically assigns). Here is a quick comparison of the two approaches: USER SELECTED SCHEDULING This approach is similar to the approach used with concert ticket sites such as Ticketmaster™. It’s how most concert tickets are sold. People compete with each other for a fixed number of tickets or appointments. Characteristics of this approach: * Appointments are available on a first-come first-serve basis. * A person chooses a preferred appointment time and location from a range of available appointments. Challenges with this approach: * First-come first-serve might not be fair. * System overloads can repeatedly shut out people with slower internet. * When many people try to reserve the same appointment slot at the same time, all but one person fails to secure the appointment which results in a poor user experience. Some people might give up trying to reserve an appointment. On the other hand, less desirable appointment slots might not be filled. * It’s tricky to prioritize based on criteria such as priority, age, or second dose status. * The desired vaccine type (Pfizer™, Moderna™, AstraZeneca™) might not be available. It could be argued that the user-selects method is not the most efficient method for vaccination scheduling. People can choose the closest vaccination center but that center might not have the greatest capacity. What’s good for one person isn’t always optimal for the population as a whole. There is no way for the system to direct a person to a vaccination center that meets the needs of the individual and is at the same time efficient for the entire population because of capacity. In addition, the system can easily be overloaded. SYSTEM AUTOMATICALLY ASSIGNED SCHEDULING With this push-based approach, people provide their information to the system and the system assigns an appointment. Characteristics of this approach: * Appointment slots are allocated based on priority. * The system allocates the best appointment time and location based on preconfigured planning constraints. Challenges with this approach: * The allocated time slot might not be convenient. * People might be more likely to reschedule. The system-automatically-assigns method is easier for people to use, is fairer, and is more efficient for vaccination appointment scheduling than the user-selects method. THE SECOND DOSE CHALLENGE Most COVID-19 vaccines require two doses. For optimal effectiveness, the second dose must be given within a specific time frame in relation to the first dose, using the same vaccine type. On top of that, different vaccines have different second-dose time frames. And within those time frames, there is a ready date (the first date that the second dose can be taken), an ideal date (the best date to take the second dose), and an end date (the last date that the second dose is considered to be effective). For example, the ideal date for the Pfizer second dose is 21 days after the first dose but the ideal date for the Moderna second dose is 28 days after the first dose. So let’s say that you start vaccinating people with the Moderna vaccine. After four weeks, you are still giving people the first dose, but now it’s time for people who already received their first dose to get their second dose. You have to decide whether to give an appointment to the person who needs the second dose or to give an appointment to someone for a first dose. That might seem like a no-brainer, but this scenario has potential complications. Let’s say that in the first week of vaccinations, you vaccinated people with a high priority but you also vaccinated other people as well because you found you had extra vaccines at the end of a day and you didn’t want to waste them. Now, four weeks later, you must choose whether to give an appointment to a first-dose high-priority person or give it to the lower-priority person that needs second dose. One solution is to equally share appointments between people receiving first and second doses, but doing this might create a backlog of people needing a second dose. If you keep giving the first dose without prioritizing people that need the second dose, eventually the backlog of people that need the second dose will snowball. The second dose vaccination date will move very far away from the ideal date and might exceed the due date which will make the first vaccination much less effective. Therefore, prioritize second-dose appointments over first-dose appointments regardless of the first-dose person’s priority rating. SOLVING THE VACCINATION APPOINTMENT SCHEDULING PROBLEM The OptaPlanner vaccination appointment scheduler uses the system-automatically-assigns method to solve the problem of vaccinating as many people as possible by using planning constraints to create a score for each person. The person’s score determines when they get an appointment. The higher the person’s score, the better chance they have of receiving an earlier appointment. Constraints are either hard, medium, or soft: * Hard constraints cannot be broken. If any hard constraint is broken, the plan is unfeasible and cannot be executed: * Capacity: Do not over-book vaccine capacity at any time at any location. * Vaccine max age: If a vaccine has a maximum age, do not administer it to people who at the time of the first dose vaccination are older than the vaccine maximum age. Ensure people are given a vaccine type appropriate for their age. For example, don’t assign a 75 year old person an appointment for a vaccine that has a maximum age restriction of 65 years. * Required vaccine type: Use the required vaccine type. For example, the second dose of a vaccine must be the same vaccine type as the first dose. * Ready date: Administer the vaccine on or after the specified date. For example, if a person receives a second dose, do not administer it before the recommended earliest possible vaccination date for the specific vaccine type (such as 26 days after the first dose). * Due date: Administer the vaccine on or before the specified date. For example, if a person receives a second dose, administer it before the recommended vaccination final due date for the specific vaccine (such as three months after the first dose). * Restrict maximum travel distance: Assign each person to one of a group of vaccination centers nearest to them. This is typically one of three centers. This restriction is calculated by travel time, not distance, so a person that lives in an urban area usually has a lower maximum distance to travel than a rural person. * Medium constraints decide who doesn’t get an appointment when there’s not enough capacity to assign appointments to everyone. This is called over-constrained planning: * Schedule second dose vaccinations: Do not leave any second dose vaccination appointments unassigned unless the ideal date falls outside of the planning window. * Schedule people based on their priority rating: Each person has a priority rating. This is typically their age but it can be much higher if they are, for example, a healthcare worker. Leave only people with the lowest priority ratings unassigned. They will be picked up in the next run. This constraint is softer than the previous constraint because the second dose is always prioritized over priority rating. * Soft constraints should not be broken: * Preferred vaccination center: If a person has a preferred vaccination center, give them an appointment at that center. * Distance: Minimize the distance that a person must travel to their assigned vaccination center. * Ideal date: Administer the vaccine on or as close to the specified date as possible. For example, if a person receives a second dose, administer it on the ideal date for the specific vaccine (such as 28 days after the first dose). This constraint is softer than the distance constraint to avoid sending people half-way across the country just to be one day closer to their ideal date. * Priority rating: Schedule people with a higher priority rating earlier in the planning window. This constraint is softer than the distance constraint to avoid sending people half-way across the country. This constraint is also softer than the ideal date constraint because the second dose is prioritized over priority rating. Hard constraints are weighted against other hard constraints. Soft constraints are weighted against other soft constraints. However, hard constraints always outweigh medium and soft constraints regardless of their respective weights. Because you have more people than you have appointment slots, you need to make tough decisions. Second dose appointments are always assigned first to avoid creating a backlog that would overwhelm you later. After that, people are assigned based on their priority rating. Everyone starts with a priority rating that is their age. Doing this prioritizes older people over younger people. After that, people that are in specific priority groups receive a few hundred extra points. This varies based on the priority of their group. For example, nurses might receive an extra 1000 points. This way, older nurses are prioritized over younger nurses and young nurses are prioritized over people who are not nurses. The following table illustrates this concept: THE SOLVER At the core of OptaPlanner is the solver, the engine that takes the problem data set and overlays the planning constraints and configurations. The problem data set includes all of the information about the people, the vaccines, and the vaccination centers. The solver works through the various combinations of data and eventually determines an optimized appointment schedule with people assigned to vaccination appointments at a specific center. The following illustration shows a schedule that the solver created: CONTINUOUS PLANNING Continuous planning is the technique of managing one or more upcoming planning periods at the same time and repeating that process monthly, weekly, daily, hourly, or even more frequently. The planning window advances incrementally by a specified interval. The following illustration shows a two week planning window that is updated daily: The two week planning window is divided in half. The first week is in the published state and the second week is in the draft state. People are assigned to appointments in both the published and draft parts of the planning window. However, only people in the published part of the planning window are notified of their appointments. The other appointments can still change easily in the next run. Doing this prevents the schedule from painting itself in a corner. For example, if a person who needs a second dose has a ready date of Monday and an ideal date of Wednesday, you don’t have to invite them for Monday if-and-only-if you can prove you can give them a draft appointment later in the week. You can determine the size of the planning window but just be mindful of the size of the problem space. The problem space is all of the various components that go into creating the schedule. So, the more days you plan ahead the larger the problem space. PINNED PLANNING ENTITIES If you are continuously planning on a daily basis, there will be appointments within the two week period that are already allocated to people. To ensure that appointments are not double-booked, you need to mark existing appointments as allocated by pinning them. Pinning is used to anchor one or more specific assignments and force OptaPlanner to schedule around those fixed assignments. A pinned planning entity, such as an appointment, doesn’t change during solving. Whether an entity is pinned or not is determined by the appointment state. If you take a look at the previous image, you can see to the left of the image that an appointment can have five states : Open, Invited, Accepted, Rejected, or Rescheduled. Table 1. Priority rating table Age Job Priority rating 60 nurse 1060 33 nurse 1033 71 retired 71 52 office worker 52 Note You don’t actually see these states directly in the quickstart demo code because the OptaPlanner engine is only interested in whether the appointment is pinned or not. So as you can see from the image, you need to be able to plan around appointments that have already been scheduled. An appointment with the Invited or Accepted state is pinned. Appointments with the Open, Reschedule, and Rejected state are not pinned and are available for scheduling. In this example, when the solver runs it searches across the entire two week planning window in both the published and draft ranges. The solver considers any unpinned entities (appointments with the Open, Reschedule, or Rejected states) in addition to the unscheduled input data, to find the optimal solution. If the solver is run daily, you will see a new day added to the schedule before you run the solver, as shown in the middle image above. The third schedule shows the results of the solver. Notice that the appointments on the new day have been assigned and Amy and Edna who were previously scheduled in the draft part of the planning window are now scheduled in the published part of the window. This was possible because Gus and Hugo requested a reschedule. This won’t cause any confusion because Amy and Edna were never notified about their draft dates. Now, because they have appointments in the published section of the planning window, they will be notified and asked to accept or reject their appointments, and their appointments are now pinned. Stay tuned. We’ll be posting a follow-up blog for a deeper, more technical look at the Optaplanner vaccination appointment scheduler quickstart. Additional resources * * * Co-authored by Emily Murphy. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lMx0uG695YE" height="1" width="1" alt=""/&gt;</content><dc:creator>pauljamesbrown</dc:creator><feedburner:origLink>https://blog.kie.org/2021/03/optimizing-covid-19-vaccination-appointment-scheduling.html</feedburner:origLink></entry><entry><title>Using Delve to debug Go programs on Red Hat Enterprise Linux</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/vTgb9gfaEL0/" /><link rel="enclosure" type="video/webm" href="https://video.fosdem.org/2020/UB2.252A/debuggingwithdelve.webm" /><category term="Go" /><category term="Linux" /><category term="Performance" /><category term="debug" /><category term="delve" /><category term="Golang" /><category term="RHEL" /><category term="starlark" /><author><name>Derek Parker</name></author><id>https://developers.redhat.com/blog/?p=695267</id><updated>2021-03-03T08:00:40Z</updated><published>2021-03-03T08:00:40Z</published><content type="html">&lt;p&gt;Delve is now available on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL). Starting in the RHEL 8.2 and &lt;code&gt;devtools-2020.2&lt;/code&gt; releases, the &lt;a href="https://developers.redhat.com/blog/category/go/"&gt;Go language&lt;/a&gt; debugger &lt;a target="_blank" rel="nofollow" href="https://github.com/go-delve/delve"&gt;Delve&lt;/a&gt; will be installed with the Go toolchain itself via the &lt;code&gt;go-toolset&lt;/code&gt; package.&lt;/p&gt; &lt;p&gt;Being tailored specifically for Go, Delve has intricate knowledge of the Go runtime and provides features and an environment not available in other debuggers. The tool aims for simplicity of use, staying out of your way as you figure out what&amp;#8217;s going wrong with your program. Delve also offers powerful features that let you debug your Go programs as quickly as possible.&lt;/p&gt; &lt;h2&gt;Installation&lt;/h2&gt; &lt;p&gt;Installation requires only one command to install both Go and Delve:&lt;/p&gt; &lt;pre&gt;sudo dnf install -y go-toolset&lt;/pre&gt; &lt;p&gt;If the command is successful, both the Go toolchain and the Delve debugger will be installed and ready to use.&lt;/p&gt; &lt;h2&gt;Advantages of Delve&lt;/h2&gt; &lt;p&gt;As I mentioned earlier, the goal of this tool is to stay out of your way as much as possible. This means removing many manual steps to provide a straightforward debugging experience.&lt;/p&gt; &lt;p&gt;As an example, the Go compiler tries to choose sensible defaults wherever feasible, so it turns on optimizations by default. The optimizations are great for running your Go programs in production but they can make debugging more difficult. Delve solves this issue by turning off optimizations automatically when building your binary. Delve can also work alongside other tools such as &lt;a target="_blank" rel="nofollow" href="https://github.com/rr-debugger/rr"&gt;Mozilla RR&lt;/a&gt;, which is currently not available as a package on RHEL, but can be built from source or installed from upstream releases.&lt;/p&gt; &lt;h2&gt;Using Delve&lt;/h2&gt; &lt;p&gt;Delve aims to be as simple to use as the Go command itself. The basic use case to start debugging a package is:&lt;/p&gt; &lt;pre&gt;dlv debug&lt;/pre&gt; &lt;p&gt;Issuing this command causes Delve to compile your program with optimizations disabled automatically, and land you at a command prompt ready to start debugging.&lt;/p&gt; &lt;p&gt;The other most common ways to begin debugging your Go program with Delve are to attach to a running process or to execute a pre-built binary:&lt;/p&gt; &lt;pre&gt;dlv attach $pid dlv exec ./path/to/binary&lt;/pre&gt; &lt;p&gt;The only potential downside to these options turns up if the binary was built with optimizations. In this case, some information might be unavailable to the debugger. So, if you want to invoke Delve on a precompiled binary, we recommend building it with optimizations disabled, using the following flags:&lt;/p&gt; &lt;pre&gt;-go build -gcflags="-N -l"&lt;/pre&gt; &lt;h2&gt;Delve tips and tricks&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s go over a few additional tips and tricks to help you make the most of Delve.&lt;/p&gt; &lt;h3&gt;Delve can call functions in the debugged process&lt;/h3&gt; &lt;p&gt;For instance, to jump to a function named &lt;code&gt;main.callme&lt;/code&gt; within Delve, enter:&lt;/p&gt; &lt;pre&gt;(dlv) call main.callme&lt;/pre&gt; &lt;h3&gt;Delve can act like strace&lt;/h3&gt; &lt;p&gt;Instead of starting a debugging session, you can connect to and trace a running binary. For example, you might trace a function named &lt;code&gt;callme&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt;dlv trace callme &amp;#62; goroutine(1): main.callme(12) =&amp;#62; (16) &lt;/pre&gt; &lt;p&gt;The output from Delve displays both the argument and the return value when the function is called—all without ever starting an interactive debug session!&lt;/p&gt; &lt;h3&gt;Delve allows different backends&lt;/h3&gt; &lt;p&gt;For instance, you can switch to the Mozilla RR backend for record-and-replay debugging as follows:&lt;/p&gt; &lt;pre&gt;dlv debug --backend=rr&lt;/pre&gt; &lt;p&gt;To learn more about this technique, please watch my talk, &lt;a target="_blank" rel="nofollow" href="https://video.fosdem.org/2020/UB2.252A/debuggingwithdelve.webm"&gt;Deterministic debugging with Delve&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Delve lets you script the debugger and add your own commands&lt;/h3&gt; &lt;p&gt;To provide an API for users to automate Delve or add new commands, Delve uses the scripting language &lt;a target="_blank" rel="nofollow" href="https://docs.bazel.build/versions/master/skylark/language.html"&gt;Starlark&lt;/a&gt;, which is similar to Python and was developed by the project that creates the &lt;a target="_blank" rel="nofollow" href="https://docs.bazel.build/versions/master/bazel-overview.html"&gt;Bazel build tool&lt;/a&gt;. See &lt;a href="https://github.com/go-delve/delve/blob/master/Documentation/cli/starlark.md" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;Delve&amp;#8217;s API documentation&lt;/a&gt; for more about this tool and how to use it.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Now that Delve is available in the &lt;code&gt;go-toolset&lt;/code&gt; package on RHEL, debugging Go programs has never been easier. Try it out and give your feedback in the &lt;a target="_blank" rel="nofollow" href="https://github.com/go-delve/delve/"&gt;upstream repo&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#38;linkname=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#38;linkname=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#38;linkname=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#38;linkname=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#38;linkname=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#38;linkname=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#38;linkname=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F03%2Fusing-delve-to-debug-go-programs-on-red-hat-enterprise-linux%2F&amp;#038;title=Using%20Delve%20to%20debug%20Go%20programs%20on%20Red%20Hat%20Enterprise%20Linux" data-a2a-url="https://developers.redhat.com/blog/2021/03/03/using-delve-to-debug-go-programs-on-red-hat-enterprise-linux/" data-a2a-title="Using Delve to debug Go programs on Red Hat Enterprise Linux"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/03/using-delve-to-debug-go-programs-on-red-hat-enterprise-linux/"&gt;Using Delve to debug Go programs on Red Hat Enterprise Linux&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/vTgb9gfaEL0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Delve is now available on Red Hat Enterprise Linux (RHEL). Starting in the RHEL 8.2 and devtools-2020.2 releases, the Go language debugger Delve will be installed with the Go toolchain itself via the go-toolset package. Being tailored specifically for Go, Delve has intricate knowledge of the Go runtime and provides features and an environment not available [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/03/using-delve-to-debug-go-programs-on-red-hat-enterprise-linux/"&gt;Using Delve to debug Go programs on Red Hat Enterprise Linux&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">695267</post-id><dc:creator>Derek Parker</dc:creator><dc:date>2021-03-03T08:00:40Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/03/using-delve-to-debug-go-programs-on-red-hat-enterprise-linux/</feedburner:origLink></entry><entry><title type="html">Quarkus 1.12.1.Final released - Bugfixes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/nzTGbCV6j8o/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-12-1-final-released/</id><updated>2021-03-03T00:00:00Z</updated><content type="html">1.12.1.Final is a maintenance release fixing bugs and improving the documentation. 1.12.1.Final is a safe upgrade for everyone using Quarkus 1.12. If you are not using 1.12 already, please refer to the 1.12 migration guide. What’s new? Full changelog You can get the full changelog of 1.12.1.Final on GitHub. Come...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/nzTGbCV6j8o" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-12-1-final-released/</feedburner:origLink></entry><entry><title type="html">Modeling and development of decision services: DMN with Kogito</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MtYk31fiENU/modeling-and-development-of-decision-services-dmn-with-kogito.html" /><author><name>Matteo Mortari</name></author><id>https://blog.kie.org/2021/03/modeling-and-development-of-decision-services-dmn-with-kogito.html</id><updated>2021-03-02T17:32:24Z</updated><content type="html">I’ve recorded the following "developer notes" as a support medium to demonstrate the progress and the current integration of several Kogito features. As I believe this could be of interest to a wider audience to have a brief overview of the many capabilities of the Kogito platform for modeling and developing decision services with DMN, I am sharing them in this post. Let us know if you find these useful and if you’d like to see more of this kind of video recordings! DMN WITH KOGITO ON QUARKUS DMN with Kogito on Quarkus * Bootstrap a new project with Kogito Maven archetype * Author DMN model in VS Code DMN modeler tooling * Generate Swagger / OAS descriptors (development support) * Test DMN REST endpoints using JUnit ( + RestAssured ) * Test DMN model using VS Code Test scenarios tooling * Inject listener use case * Test DMN on Quarkus service using Quarkus dev-mode locally * Generated REST API for DMN models with Swagger/OAS descriptors and internals * GraalVM Native Image / Mandrel native support DMN WITH KOGITO ON SPRING BOOT DMN with Kogito on Spring Boot * Bootstrap a new project with Kogito Maven archetype * Author DMN model in VS Code DMN modeler tooling * Generated Swagger / OAS descriptors (development support) and Test DMN SpringBoot service locally * Test DMN REST endpoints using JUnit ( + RestAssured ) * Test DMN model using VS Code Test scenarios tooling The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MtYk31fiENU" height="1" width="1" alt=""/&gt;</content><dc:creator>Matteo Mortari</dc:creator><feedburner:origLink>https://blog.kie.org/2021/03/modeling-and-development-of-decision-services-dmn-with-kogito.html</feedburner:origLink></entry><entry><title>Packaging APIs for consumers with Red Hat 3scale API Management</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Y16ej0rYAEA/" /><category term="DevOps" /><category term="Event-Driven" /><category term="Kubernetes" /><category term="3scale API Management" /><category term="API consumers" /><category term="API plans" /><category term="API policies" /><author><name>Satya Jayanti</name></author><id>https://developers.redhat.com/blog/?p=869597</id><updated>2021-03-02T08:00:12Z</updated><published>2021-03-02T08:00:12Z</published><content type="html">&lt;p&gt;One of an API management platform&amp;#8217;s core functionalities is defining and enforcing policies, business domain rate limits, and pricing rules for securing API endpoints. As an API provider, you sometimes need to make the same backend API available for different consumer segments using these terms. In this article, you will learn about using &lt;a href="https://developers.redhat.com/products/3scale/overview"&gt;Red Hat 3scale API Management&lt;/a&gt; to package APIs for different consumers, including internal and external developers and strategic partners. See the end of the article for a video tutorial that guides you through using 3scale API Management to create and configure the packages that you will learn about in this article.&lt;/p&gt; &lt;h2&gt;About Red Hat 3scale API Management&lt;/h2&gt; &lt;p&gt;3scale API Management is a scalable, hybrid cloud API management framework that is part of the &lt;a href="https://developers.redhat.com/integration"&gt;Red Hat Integration&lt;/a&gt; product portfolio. Figure 1 is a simplified view of the &lt;a target="_blank" rel="nofollow" href="https://www.3scale.net"&gt;3scale API Management&lt;/a&gt; framework.&lt;/p&gt; &lt;div id="attachment_742967" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/3scale-High-level-diagram.png"&gt;&lt;img aria-describedby="caption-attachment-742967" class="hoverZoomLink wp-image-742967 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/3scale-High-level-diagram-1024x698.png" alt="The flow of interactions between the API consumer, API manager, and API gateway in 3scale API Management." width="640" height="436" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/3scale-High-level-diagram-1024x698.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/3scale-High-level-diagram-300x205.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/3scale-High-level-diagram-768x524.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/3scale-High-level-diagram.png 1154w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-742967" class="wp-caption-text"&gt;Figure 1: A high-level view of 3scale API Management.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The &lt;em&gt;API Manager&lt;/em&gt; is the framework&amp;#8217;s control plane. It provides an interface for the API provider to create users, accounts, policies, and services. The &lt;em&gt;API Gateway&lt;/em&gt; (APIcast) enforces the policies for APIs in the data plane.&lt;/p&gt; &lt;h2&gt;Policies for  API access&lt;/h2&gt; &lt;p&gt;We can use 3scale API Management to create consumer segments where distinct policies are enforced for the same API. For example, let&amp;#8217;s say we need to expose a single API endpoint to three different consumer audiences: internal developers, external developers, and strategic partners. Table 1 shows a sample scenario of the packages that we could create for each audience.&lt;/p&gt; &lt;table align="”center”"&gt; &lt;caption&gt;&lt;strong&gt;Table 1: A basic application plan for three audiences&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Package&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Rate limits&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Pricing rules&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Internal developers&lt;/td&gt; &lt;td&gt;None&lt;/td&gt; &lt;td&gt;Free&lt;/td&gt; &lt;td&gt;Internal&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;External developers&lt;/td&gt; &lt;td&gt;10 calls per minute&lt;/td&gt; &lt;td&gt;$0.01 per call&lt;/td&gt; &lt;td&gt;Basic&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic partners&lt;/td&gt; &lt;td&gt;1 million calls per day&lt;/td&gt; &lt;td&gt;$100 per month&lt;/td&gt; &lt;td&gt;Premium&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Although the rate limit is set to &amp;#8220;None&amp;#8221; for internal developers, it is better to set a high rate limit to prevent distributed denial-of-service (DDoS) attacks. Additionally, while the rate limit for strategic partners is expressed per day, it would be better to set it on a per-minute basis. Doing that would prevent overloading systems with heavy loads in short bursts.&lt;/p&gt; &lt;p&gt;Figure 2 shows the API packages from Table 1.&lt;/p&gt; &lt;div id="attachment_743007" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Packaging.png"&gt;&lt;img aria-describedby="caption-attachment-743007" class="hoverZoomLink wp-image-743007 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Packaging-1024x692.png" alt="A visual representation of the API packages from Table 1." width="640" height="433" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Packaging-1024x692.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Packaging-300x203.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Packaging-768x519.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Packaging.png 1286w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-743007" class="wp-caption-text"&gt;Figure 2: API packages for internal developers, external developers, and strategic partners.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The &lt;em&gt;Rate limits&lt;/em&gt; policy, shown in Figure 2, enforces call limits on APIs. Limits are defined for each method, and the same package can enforce different limits for each API method. &lt;em&gt;Pricing rules&lt;/em&gt; are used to enable metering and chargeback for API calls. Pricing rules are defined for each API method, and the same package can enforce different pricing rules for each API method. Finally, the &lt;em&gt;Features&lt;/em&gt; policy lets us define multiple features for each package. 3scale API Management adds metadata tags to each package to uniquely identify and map its available features.&lt;/p&gt; &lt;p&gt;3scale API Management&amp;#8217;s packaging scenario is common, and most API management platforms support something similar. In the following sections, we will look at the different types of plans available from 3scale API Management.&lt;/p&gt; &lt;h2&gt;Application plans&lt;/h2&gt; &lt;p&gt;&lt;em&gt;Application plans&lt;/em&gt; establish the rules (limits, pricing, features) for using an API. Every application request to the API happens within the constraints of an application plan. Every API in 3scale API Management must have at least one defined application plan. It is also common to define multiple plans to target different audiences using the same API. Figure 3 shows the relationship of the API to application plans, consumer audiences, and policies.&lt;/p&gt; &lt;div id="attachment_742997" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Application-Plans.png"&gt;&lt;img aria-describedby="caption-attachment-742997" class="hoverZoomLink wp-image-742997 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Application-Plans-1024x875.png" alt="A single API with three different audiences and their respective application plans and policies." width="640" height="547" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Application-Plans-1024x875.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Application-Plans-300x256.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Application-Plans-768x656.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Application-Plans.png 1220w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-742997" class="wp-caption-text"&gt;Figure 3: A single API can have multiple application plans enforcing different policies for different users.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Each consumer application is mapped uniquely to a single application plan. When the application requests an API, 3scale API Management applies the rate limits and pricing rules for that application and updates its usage statistics. Application plans are the lowest granularity of control available in 3scale API Management. Most packaging requirements can be met by using one or more application plans per API.&lt;/p&gt; &lt;h2&gt;Beyond application plans&lt;/h2&gt; &lt;p&gt;In some cases, we need to use specialized plans to define policies for multiple application plans for an API or developer account. A default plan is available to all API providers, but specialized plans—which define complex relationships between services, applications, and accounts—must be explicitly enabled. The decision to use one or more specialized plans should be considered during the API design phase and documented in detail to avoid unexpected outcomes. The next sections introduce service plans and account plans.&lt;/p&gt; &lt;h3&gt;Service plans&lt;/h3&gt; &lt;p&gt;We can use service plans to subscribe consumers to APIs. Service subscriptions are enabled by default in 3scale API Management, and only one service plan is enabled per subscription. A service plan provides service-level features and plans for all applications consuming the service under that plan.&lt;/p&gt; &lt;p&gt;As an example, the plan described in Table 2 adds a new feature to the application plans we developed in the previous section.&lt;/p&gt; &lt;table align="”center”"&gt; &lt;caption&gt;&lt;strong&gt;Table 2: Adding new features to the three basic application plans&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Package&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Rate limits&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Pricing rules&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Internal developers&lt;/td&gt; &lt;td&gt;None&lt;/td&gt; &lt;td&gt;Free&lt;/td&gt; &lt;td&gt;Internal, &lt;b&gt;developers&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;External developers&lt;/td&gt; &lt;td&gt;10 calls per minute&lt;/td&gt; &lt;td&gt;$0.01 per call&lt;/td&gt; &lt;td&gt;Basic, &lt;b&gt;developers&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic partners&lt;/td&gt; &lt;td&gt;1 million calls per day&lt;/td&gt; &lt;td&gt;$100 per month&lt;/td&gt; &lt;td&gt;Premium, &lt;b&gt;partners&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;We could set up the new features individually for each application plan. However, it would be better to define the “default” service plan features and enable corresponding features in the application plans as required.&lt;/p&gt; &lt;p&gt;Table 3 describes a more complex scenario, where the API provider needs to provide two or more application plans for partners.&lt;/p&gt; &lt;table align="”center”"&gt; &lt;caption&gt;&lt;strong&gt;Table 3: Multiple application plans&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Package&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Rate limits&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Pricing rules&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic Partners Bronze Plan&lt;/td&gt; &lt;td&gt;100,000 calls per day&lt;/td&gt; &lt;td&gt;$30 per month&lt;/td&gt; &lt;td&gt;Premium, partners, bronze, developers&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic Partners Silver Plan&lt;/td&gt; &lt;td&gt;500,000 calls per day&lt;/td&gt; &lt;td&gt;$60 per month&lt;/td&gt; &lt;td&gt;Premium, partners, silver, testing&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic Partners Gold Plan&lt;/td&gt; &lt;td&gt;1 million calls per day&lt;/td&gt; &lt;td&gt;$100 per month&lt;/td&gt; &lt;td&gt;Premium, partners, gold, production&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;In this case, the API provider could allow a single partner account to sign up for multiple plans. For example, a strategic partner could use the bronze plan for applications in development, the silver plan for quality assurance (QA), and the gold plan for production applications. To provide the partner with standard pricing across all application plans, we could use the service plan described in Table 4.&lt;/p&gt; &lt;table align="”center”"&gt; &lt;caption&gt;&lt;strong&gt;Table 4: Introducing a service plan&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Service plan&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Set up fees&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Pricing rules&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic Partners Premium Plan&lt;/td&gt; &lt;td&gt;$50&lt;/td&gt; &lt;td&gt;$100 per month&lt;/td&gt; &lt;td&gt;Premium, partners, customers&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Figure 4 shows a typical scenario using service plans and application plans in tandem.&lt;/p&gt; &lt;div id="attachment_742987" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Service-Plans.png"&gt;&lt;img aria-describedby="caption-attachment-742987" class="hoverZoomLink wp-image-742987 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Service-Plans-1024x786.png" alt="A single API with two different service plans: One for developers and one for strategic partners." width="640" height="491" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Service-Plans-1024x786.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Service-Plans-300x230.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Service-Plans-768x589.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Service-Plans.png 1220w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-742987" class="wp-caption-text"&gt;Figure 4: Combining service plans and application plans in 3scale API Management.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;To recap, consider using custom service plans for these types of use cases:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Custom features that multiple application plans can inherit.&lt;/li&gt; &lt;li&gt;A custom trial period that is applicable across multiple application plans for the same API.&lt;/li&gt; &lt;li&gt;Set up fees or fixed fees that are applicable across multiple application plans for the same API.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Account plans&lt;/h3&gt; &lt;p&gt;&lt;em&gt;Account plans&lt;/em&gt; are used to apply subscription criteria to consumer accounts. Instead of managing API access, like application plans and service plans, this plan packages accounts and applies the account plan across all the APIs accessed by a given account. Account plans create &amp;#8220;tiers&amp;#8221; of usage within the developer portal, allowing you to distinguish between grades of support, content, and other services that partners at different levels receive.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s say that an API provider wants to cater to three different partner levels, with policies for each, as shown in Table 5.&lt;/p&gt; &lt;table align="”center”"&gt; &lt;caption&gt;&lt;strong&gt;Table 5: A sample account plan for three levels of partners&lt;/strong&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Package&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Set up cost&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Monthly cost&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic Partners Bronze Plan&lt;/td&gt; &lt;td&gt;Free&lt;/td&gt; &lt;td&gt;$30 per month&lt;/td&gt; &lt;td&gt;Premium, partners, bronze, no support&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic Partners Silver Plan&lt;/td&gt; &lt;td&gt;$50&lt;/td&gt; &lt;td&gt;$60 per month&lt;/td&gt; &lt;td&gt;Premium, partners, silver, standard support&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strategic Partners Gold Plan&lt;/td&gt; &lt;td&gt;$100&lt;/td&gt; &lt;td&gt;$100 per month&lt;/td&gt; &lt;td&gt;Premium, partners, gold, 24/7 support, dedicated account&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The provider chooses to charge a fixed monthly cost and setup cost instead of charging per API or application plan. In this case, it makes sense to have a plan operate at the account level so that the same policies apply to all the APIs and applications associated with that account. The API provider could also create different setup costs and support plans for different sets of customer accounts. Figure 5 illustrates the relationship between account plans and APIs.&lt;/p&gt; &lt;div id="attachment_742977" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Account-Plans.png"&gt;&lt;img aria-describedby="caption-attachment-742977" class="hoverZoomLink wp-image-742977 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Account-Plans-1024x866.png" alt="Internal developers receive a basic plan, while external developers and strategic partners receive a standard trial plan." width="640" height="541" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Account-Plans-1024x866.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Account-Plans-300x254.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Account-Plans-768x649.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/API-Account-Plans.png 1234w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-742977" class="wp-caption-text"&gt;Figure 5: Use an account plan to apply the same policies to all APIs and applications associated with an account.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;3scale API Management provides a default account plan for all developer accounts. The default plan ensures that application access is controlled through individual service and application plans. If you needed to define features for a set of developer accounts independent of the number of applications, you might consider implementing an account plan. Account plans also work well when the setup fee, usage fee, or the length of a trial period is fixed for the account regardless of the number of APIs subscribed.&lt;/p&gt; &lt;h2&gt;Watch the video&lt;/h2&gt; &lt;p&gt;Watch the following video for a guide to using 3scale API Management to package and combine API plans for a variety of consumers.&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/rs-iRUgN8Ok?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;As you have seen, it is possible to accomplish many complex API packaging scenarios using 3scale API Management and the right combination of account plans, service plans, and application plans. This article discussed strategies for packaging a single API backend endpoint. 3scale API Management also supports an &lt;a href="https://developers.redhat.com/blog/2019/12/03/apis-as-a-product-get-started-in-no-time/"&gt;API-as-a-product&lt;/a&gt; functionality that lets us package multiple backend APIs using the same policies and plans. My next article in this series introduces the API-as-a-product functionality and use cases.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#38;linkname=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#38;linkname=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#38;linkname=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#38;linkname=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#38;linkname=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#38;linkname=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#38;linkname=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F02%2Fpackaging-apis-for-consumers-with-red-hat-3scale-api-management%2F&amp;#038;title=Packaging%20APIs%20for%20consumers%20with%20Red%20Hat%203scale%20API%20Management" data-a2a-url="https://developers.redhat.com/blog/2021/03/02/packaging-apis-for-consumers-with-red-hat-3scale-api-management/" data-a2a-title="Packaging APIs for consumers with Red Hat 3scale API Management"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/02/packaging-apis-for-consumers-with-red-hat-3scale-api-management/"&gt;Packaging APIs for consumers with Red Hat 3scale API Management&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Y16ej0rYAEA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;One of an API management platform&amp;#8217;s core functionalities is defining and enforcing policies, business domain rate limits, and pricing rules for securing API endpoints. As an API provider, you sometimes need to make the same backend API available for different consumer segments using these terms. In this article, you will learn about using Red Hat [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/02/packaging-apis-for-consumers-with-red-hat-3scale-api-management/"&gt;Packaging APIs for consumers with Red Hat 3scale API Management&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/02/packaging-apis-for-consumers-with-red-hat-3scale-api-management/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">869597</post-id><dc:creator>Satya Jayanti</dc:creator><dc:date>2021-03-02T08:00:12Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/02/packaging-apis-for-consumers-with-red-hat-3scale-api-management/</feedburner:origLink></entry><entry><title type="html">New enhancements on DMN editor decision services experience</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/4MKIpnOTCag/new-enhancements-on-dmn-editor-decision-services-experience.html" /><author><name>Guilherme Carreiro</name></author><id>https://blog.kie.org/2021/03/new-enhancements-on-dmn-editor-decision-services-experience.html</id><updated>2021-03-01T23:00:00Z</updated><content type="html">The user experience for decision service nodes is something we’re incrementally enhancing in the DMN editor. will introduce a new feature that significantly enhances how users call decision services. Imagine you have a DMN model like this one: Also, imagine that you need to invoke the decision service “user message” into the “Example” node with a Literal Expression. How can you do that? &#x1f914; You probably would need to guess the parameters’ order, which is quite frustrating (of course – we may be wrong!). On Kogito 0.8.4, users will be able to select a decision service and see the order of parameters, like this: So, now it’s much easier to call “user message” now, as we can clearly see the order of our parameters is “Age (number)” and then “Name (string)”. Also, now we know the answer to the question above and we can call our decision service: If you’re wondering what this model returns, check this example of DMN model call and output: require 'httparty' body = { 'Name': 'Kojima', 'Age': 57, } resp = HTTParty.post("http://localhost:8080/example", body: body.to_json, headers: { 'Content-Type': 'application/json', 'Accept': 'application/json' }, basic_auth: { username: 'kieserver', password: 'kieserver1!' }) puts resp # { # "user message":"function user message( Age, Name )", # "upcase":"THE USER KOJIMA IS 57 YEARS OLD.", # "Example":"THE USER GUILHERME IS 29 YEARS OLD.", # "concat":"The user Kojima is 57 years old.", # "Age":57, # "Name":"Kojima" # } Straightforward, right? &#x1f642; We’ll release Kogito 0.8.4 in a few days with other surprising news… but, if you really wanna try it right now, download my latest VSCode plugin build . Stay tuned! &#x1f642; The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/4MKIpnOTCag" height="1" width="1" alt=""/&gt;</content><dc:creator>Guilherme Carreiro</dc:creator><feedburner:origLink>https://blog.kie.org/2021/03/new-enhancements-on-dmn-editor-decision-services-experience.html</feedburner:origLink></entry><entry><title type="html">Business optimisation architecture - Example planning optimisation</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/UvQ57-HczL8/business-optimisation-example-planning-optimisation-architecture.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/O4R26YNWUdk/business-optimisation-example-planning-optimisation-architecture.html</id><updated>2021-03-01T06:00:00Z</updated><content type="html">Part 3 - Example planning optimisation In my  I shared the logical view of the business optimisation use case for retail stores. The process was laid out how I've approached the use case and how portfolio solutions are the base for researching a generic architectural blueprint.  It started with laying out the process of how I've approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. Having completed our discussions on the logical view of the blueprint, it's now time to look at a specific example. This article walks you through an example optimisation scenario showing how expanding the previously discussed elements provides a blueprint for your own optimisation scenarios. BLUEPRINTS REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common blueprint that was uncovered researching those solutions. It's my intent to provide a blueprint that provides guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architectural blueprint, but I've chosen a format that I hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a look at the details in this blueprint and outline the solution. STORE OPTIMISATION ARCHITECTURE The example blueprint shown in the figure titled Schematic - Business optimisation outlines how optimisation ties into your architecture. In this example, starting from the left we see a business owner and developer providing the input needed for the retail planning services. These inputs are constraints (both hard and soft), resource availability, and business goals to be achieved.  While this might look like something that the business owner and developer are doing into the fully deployed solution, it's really using the previously covered showcased in that blueprint. For simplicity, we've included the planning and constraint development aspects here to help with an understanding that business owners are involved. The planning services would then be triggered by external systems that have been given access through the API management element to start, provide input, or retreive planning optimisation results. It's also possible that the retail planning services are providing input into any number of retail processes.  The retail processes leverage retail decision microservices that contain the centralised store logic for both process and integration microservices are making extensive use of. Integration microservices are also the integration point to all external communications with external systems and retail systems that might be internal to the store organisation but hosted external to the physical location of the business optimisation architecture. Data access is shown at the bottom through the Retail Data Framework, another full architecture blueprint itself with details to be found how it's organised. This access for the retail planning services is arranged by the integration data microservices allowing for clean separation of integration points between critical demarcation lines of your architecture. While the business owner and developer are working on the deployment of the needed retail planning services, at runtime the rest of the elements in this diagram are leveraging these optimisation planning services to achieve desired outcomes.  The diagram might give the impression that this is a single store solution, but it can also be seen in the context of a centralised architecture in the retail organisation where the external systems and triggers are those of satellite stores or warehouses. The stores and warehouses are all looking to make use of the planning and optimising services for better store delivery routing, planning more efficient staff rostering,  and for improving efficiency of local tasks. WHAT'S NEXT THIS WAS JUST A SHORT OVERVIEW OF A PLANNING OPTIMISATION ARCHITECTURE THAT PROVIDES YOU WITH A MAP TO SOLVE YOUR OWN BUSINESS OPTIMISATION CHALLENGES.  AN OVERVIEW OF THIS SERIES ON THE BUSINESS OPTIMISATION PORTFOLIO ARCHITECTURE BLUEPRINT CAN BE FOUND HERE: 1. 2. 3.   4. CATCH UP ON ANY ARTICLES YOU MISSED BY FOLLOWING ONE OF THE LINKS ABOVE. NEXT IN THIS SERIES, TAKING A LOOK AT AN USING THIS ARCHITECTURE BLUEPRINT FOR BUSINESS OPTIMISATION. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/UvQ57-HczL8" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/O4R26YNWUdk/business-optimisation-example-planning-optimisation-architecture.html</feedburner:origLink></entry></feed>
